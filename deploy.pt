name: "darknet-16c-16x-3d"
layer {
  name: "input"
  type: "Input"
  top: "data"
  input_param {
    shape {
      dim: 1
      dim: 384
      dim: 960
      dim: 3
    }
  }
}
layer {
  name: "data_perm"
  type: "Permute"
  bottom: "data"
  top: "data_perm"
  permute_param {
    order: 0
    order: 3
    order: 1
    order: 2
  }
}
layer {
  name: "data_scale"
  type: "Power"
  bottom: "data_perm"
  top: "data_scale"
  power_param {
    power: 1.0
    scale: 0.00392156885937
    shift: 0.0
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data_scale"
  top: "conv1"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "pool1"
  top: "conv2"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv2_relu"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "pool2"
  type: "Pooling"
  bottom: "conv2"
  top: "pool2"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv3_1"
  type: "Convolution"
  bottom: "pool2"
  top: "conv3_1"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv3_1_relu"
  type: "ReLU"
  bottom: "conv3_1"
  top: "conv3_1"
}
layer {
  name: "conv3_2"
  type: "Convolution"
  bottom: "conv3_1"
  top: "conv3_2"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv3_2_relu"
  type: "ReLU"
  bottom: "conv3_2"
  top: "conv3_2"
}
layer {
  name: "conv3_3"
  type: "Convolution"
  bottom: "conv3_2"
  top: "conv3_3"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv3_3_relu"
  type: "ReLU"
  bottom: "conv3_3"
  top: "conv3_3"
}
layer {
  name: "pool3"
  type: "Pooling"
  bottom: "conv3_3"
  top: "pool3"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv4_1"
  type: "Convolution"
  bottom: "pool3"
  top: "conv4_1"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv4_1_relu"
  type: "ReLU"
  bottom: "conv4_1"
  top: "conv4_1"
}
layer {
  name: "conv4_2"
  type: "Convolution"
  bottom: "conv4_1"
  top: "conv4_2"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv4_2_relu"
  type: "ReLU"
  bottom: "conv4_2"
  top: "conv4_2"
}
layer {
  name: "conv4_3"
  type: "Convolution"
  bottom: "conv4_2"
  top: "conv4_3"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv4_3_relu"
  type: "ReLU"
  bottom: "conv4_3"
  top: "conv4_3"
}
layer {
  name: "pool4"
  type: "Pooling"
  bottom: "conv4_3"
  top: "pool4"
  pooling_param {
    pool: MAX
    kernel_size: 2
    stride: 2
    pad: 0
  }
}
layer {
  name: "conv5_1"
  type: "Convolution"
  bottom: "pool4"
  top: "conv5_1"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv5_1_relu"
  type: "ReLU"
  bottom: "conv5_1"
  top: "conv5_1"
}
layer {
  name: "conv5_2"
  type: "Convolution"
  bottom: "conv5_1"
  top: "conv5_2"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv5_2_relu"
  type: "ReLU"
  bottom: "conv5_2"
  top: "conv5_2"
}
layer {
  name: "conv5_3"
  type: "Convolution"
  bottom: "conv5_2"
  top: "conv5_3"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv5_3_relu"
  type: "ReLU"
  bottom: "conv5_3"
  top: "conv5_3"
}
layer {
  name: "conv5_4"
  type: "Convolution"
  bottom: "conv5_3"
  top: "conv5_4"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv5_4_relu"
  type: "ReLU"
  bottom: "conv5_4"
  top: "conv5_4"
}
layer {
  name: "conv5_5"
  type: "Convolution"
  bottom: "conv5_4"
  top: "conv5_5"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv5_5_relu"
  type: "ReLU"
  bottom: "conv5_5"
  top: "conv5_5"
}
layer {
  name: "pool5"
  type: "Pooling"
  bottom: "conv5_5"
  top: "pool5"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 1
    pad: 1
  }
}
layer {
  name: "conv6_1_nodilate"
  type: "Convolution"
  bottom: "pool5"
  top: "conv6_1"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 2
    kernel_size: 5
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv6_1_relu"
  type: "ReLU"
  bottom: "conv6_1"
  top: "conv6_1"
}
layer {
  name: "conv6_2"
  type: "Convolution"
  bottom: "conv6_1"
  top: "conv6_2"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv6_2_relu"
  type: "ReLU"
  bottom: "conv6_2"
  top: "conv6_2"
}
layer {
  name: "conv6_3"
  type: "Convolution"
  bottom: "conv6_2"
  top: "conv6_3"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv6_3_relu"
  type: "ReLU"
  bottom: "conv6_3"
  top: "conv6_3"
}
layer {
  name: "conv6_4"
  type: "Convolution"
  bottom: "conv6_3"
  top: "conv6_4"
  convolution_param {
    num_output: 256
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv6_4_relu"
  type: "ReLU"
  bottom: "conv6_4"
  top: "conv6_4"
}
layer {
  name: "conv6_5"
  type: "Convolution"
  bottom: "conv6_4"
  top: "conv6_5"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv6_5_relu"
  type: "ReLU"
  bottom: "conv6_5"
  top: "conv6_5"
}
layer {
  name: "conv7_1"
  type: "Convolution"
  bottom: "conv6_5"
  top: "conv7_1"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv7_1_relu"
  type: "ReLU"
  bottom: "conv7_1"
  top: "conv7_1"
}
layer {
  name: "conv7_2"
  type: "Convolution"
  bottom: "conv7_1"
  top: "conv7_2"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv7_2_relu"
  type: "ReLU"
  bottom: "conv7_2"
  top: "conv7_2"
}
layer {
  name: "concat8"
  type: "Concat"
  bottom: "conv5_5"
  bottom: "conv7_2"
  top: "concat8"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv9"
  type: "Convolution"
  bottom: "concat8"
  top: "conv9"
  convolution_param {
    num_output: 512
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
    dilation: 1
  }
}
layer {
  name: "conv9_relu"
  type: "ReLU"
  bottom: "conv9"
  top: "conv9"
}
layer {
  name: "conv_final"
  type: "Convolution"
  bottom: "conv9"
  top: "conv_final"
  convolution_param {
    num_output: 144
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "conv_final_permute"
  type: "Permute"
  bottom: "conv_final"
  top: "conv_final_permute"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "slice"
  type: "Slice"
  bottom: "conv_final_permute"
  top: "loc_pred"
  top: "obj_perm"
  top: "cls_perm"
  slice_param {
    slice_point: 64
    slice_point: 80
    axis: 3
  }
}
layer {
  name: "cls_reshape"
  type: "Reshape"
  bottom: "cls_perm"
  top: "cls_reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: -1
      dim: 4
    }
  }
}
layer {
  name: "cls_pred_prob"
  type: "Softmax"
  bottom: "cls_reshape"
  top: "cls_pred_prob"
  softmax_param {
    axis: 3
  }
}
layer {
  name: "cls_pred"
  type: "Reshape"
  bottom: "cls_pred_prob"
  top: "cls_pred"
  reshape_param {
    shape {
      dim: 0
      dim: 0
      dim: -1
      dim: 64
    }
  }
}
layer {
  name: "obj_pred"
  type: "Sigmoid"
  bottom: "obj_perm"
  top: "obj_pred"
}
layer {
  name: "ori_origin"
  type: "Convolution"
  bottom: "conv9"
  top: "ori_origin"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "ori_pred"
  type: "Permute"
  bottom: "ori_origin"
  top: "ori_pred"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "dim_origin"
  type: "Convolution"
  bottom: "conv9"
  top: "dim_origin"
  convolution_param {
    num_output: 48
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "dim_pred"
  type: "Permute"
  bottom: "dim_origin"
  top: "dim_pred"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "lof_origin"
  type: "Convolution"
  bottom: "conv9"
  top: "lof_origin"
  propagate_down: false
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "lof_perm"
  type: "Permute"
  bottom: "lof_origin"
  top: "lof_pred"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "lor_origin"
  type: "Convolution"
  bottom: "conv9"
  top: "lor_origin"
  propagate_down: false
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 1
    stride: 1
  }
}
layer {
  name: "lor_perm"
  type: "Permute"
  bottom: "lor_origin"
  top: "lor_pred"
  permute_param {
    order: 0
    order: 2
    order: 3
    order: 1
  }
}
layer {
  name: "reduce1_lane"
  type: "Convolution"
  bottom: "concat8"
  top: "reduce1_lane"
  convolution_param {
    num_output: 128
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reduce1_lane_relu"
  type: "ReLU"
  bottom: "reduce1_lane"
  top: "reduce1_lane"
}
layer {
  name: "deconv1_lane"
  type: "Deconvolution"
  bottom: "reduce1_lane"
  top: "deconv1_lane"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 0
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "deconv1_lane_relu"
  type: "ReLU"
  bottom: "deconv1_lane"
  top: "deconv1_lane"
}
layer {
  name: "reorg4"
  type: "Convolution"
  bottom: "conv4_3"
  top: "reorg4"
  convolution_param {
    num_output: 64
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reorg4_relu"
  type: "ReLU"
  bottom: "reorg4"
  top: "reorg4"
}
layer {
  name: "concat4"
  type: "Concat"
  bottom: "reorg4"
  bottom: "deconv1_lane"
  top: "concat4"
  concat_param {
    axis: 1
  }
}
layer {
  name: "reduce2_lane"
  type: "Convolution"
  bottom: "concat4"
  top: "reduce2_lane"
  convolution_param {
    num_output: 64
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reduce2_lane_relu"
  type: "ReLU"
  bottom: "reduce2_lane"
  top: "reduce2_lane"
}
layer {
  name: "deconv2_lane"
  type: "Deconvolution"
  bottom: "reduce2_lane"
  top: "deconv2_lane"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 0
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "deconv2_lane_relu"
  type: "ReLU"
  bottom: "deconv2_lane"
  top: "deconv2_lane"
}
layer {
  name: "reorg3"
  type: "Convolution"
  bottom: "conv3_3"
  top: "reorg3"
  convolution_param {
    num_output: 32
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reorg3_relu"
  type: "ReLU"
  bottom: "reorg3"
  top: "reorg3"
}
layer {
  name: "concat3"
  type: "Concat"
  bottom: "reorg3"
  bottom: "deconv2_lane"
  top: "concat3"
  concat_param {
    axis: 1
  }
}
layer {
  name: "reduce3_lane"
  type: "Convolution"
  bottom: "concat3"
  top: "reduce3_lane"
  convolution_param {
    num_output: 32
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reduce3_lane_relu"
  type: "ReLU"
  bottom: "reduce3_lane"
  top: "reduce3_lane"
}
layer {
  name: "deconv3_lane"
  type: "Deconvolution"
  bottom: "reduce3_lane"
  top: "deconv3_lane"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 0
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "deconv3_lane_relu"
  type: "ReLU"
  bottom: "deconv3_lane"
  top: "deconv3_lane"
}
layer {
  name: "reorg2"
  type: "Convolution"
  bottom: "conv2"
  top: "reorg2"
  convolution_param {
    num_output: 16
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reorg2_relu"
  type: "ReLU"
  bottom: "reorg2"
  top: "reorg2"
}
layer {
  name: "concat2"
  type: "Concat"
  bottom: "reorg2"
  bottom: "deconv3_lane"
  top: "concat2"
  concat_param {
    axis: 1
  }
}
layer {
  name: "reduce4_lane"
  type: "Convolution"
  bottom: "concat2"
  top: "reduce4_lane"
  convolution_param {
    num_output: 16
    bias_term: true
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reduce4_lane_relu"
  type: "ReLU"
  bottom: "reduce4_lane"
  top: "reduce4_lane"
}
layer {
  name: "deconv4_lane"
  type: "Deconvolution"
  bottom: "reduce4_lane"
  top: "deconv4_lane"
  convolution_param {
    num_output: 8
    bias_term: true
    pad: 0
    kernel_size: 2
    stride: 2
  }
}
layer {
  name: "deconv4_lane_relu"
  type: "ReLU"
  bottom: "deconv4_lane"
  top: "deconv4_lane"
}
layer {
  name: "reorg1"
  type: "Convolution"
  bottom: "conv1"
  top: "reorg1"
  convolution_param {
    num_output: 8
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "reorg1_relu"
  type: "ReLU"
  bottom: "reorg1"
  top: "reorg1"
}
layer {
  name: "concat1"
  type: "Concat"
  bottom: "reorg1"
  bottom: "deconv4_lane"
  top: "concat1"
  concat_param {
    axis: 1
  }
}
layer {
  name: "conv_out"
  type: "Convolution"
  bottom: "concat1"
  top: "conv_out"
  convolution_param {
    num_output: 4
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
  }
}
layer {
  name: "seg_prob"
  type: "Softmax"
  bottom: "conv_out"
  top: "seg_prob"
  softmax_param {
    axis: 1
  }
}
